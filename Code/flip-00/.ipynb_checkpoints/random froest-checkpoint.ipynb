{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  shop_id  item_id\n",
      "0            0        5     5037\n",
      "1            1        5     5320\n",
      "2            2        5     5233\n",
      "3            3        5     5232\n",
      "4            4        5     5268\n",
      "...        ...      ...      ...\n",
      "214195  214195       45    18454\n",
      "214196  214196       45    16188\n",
      "214197  214197       45    15757\n",
      "214198  214198       45    19648\n",
      "214199  214199       45      969\n",
      "\n",
      "[214200 rows x 3 columns]\n",
      "               date  date_block_num  shop_id  item_id  item_price  \\\n",
      "0        02.01.2013               0       59    22154      999.00   \n",
      "1        03.01.2013               0       25     2552      899.00   \n",
      "2        05.01.2013               0       25     2552      899.00   \n",
      "3        06.01.2013               0       25     2554     1709.05   \n",
      "4        15.01.2013               0       25     2555     1099.00   \n",
      "...             ...             ...      ...      ...         ...   \n",
      "2935844  10.10.2015              33       25     7409      299.00   \n",
      "2935845  09.10.2015              33       25     7460      299.00   \n",
      "2935846  14.10.2015              33       25     7459      349.00   \n",
      "2935847  22.10.2015              33       25     7440      299.00   \n",
      "2935848  03.10.2015              33       25     7460      299.00   \n",
      "\n",
      "         item_cnt_day  \n",
      "0                 1.0  \n",
      "1                 1.0  \n",
      "2                -1.0  \n",
      "3                 1.0  \n",
      "4                 1.0  \n",
      "...               ...  \n",
      "2935844           1.0  \n",
      "2935845           1.0  \n",
      "2935846           1.0  \n",
      "2935847           1.0  \n",
      "2935848           1.0  \n",
      "\n",
      "[2935849 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import datetime\n",
    "\n",
    "train_df = pd.read_csv(\"../Data/sales_train.csv\")\n",
    "test_df = pd.read_csv(\"../Data/test.csv\")\n",
    "submission_df = pd.read_csv(\"../Data/sample_submission.csv\")\n",
    "items_df = pd.read_csv(\"../Data/items.csv\")\n",
    "item_categories_df = pd.read_csv(\"../Data/item_categories.csv\")\n",
    "shops_df = pd.read_csv(\"../Data/shops.csv\")\n",
    "\n",
    "feature_count = 25\n",
    "items_df['item_name_length'] = items_df['item_name'].map(lambda x : len(x)) #Length of each item_name(including punctuation in the item_name)\n",
    "items_df['item_name_word_count'] = items_df['item_name'].map(lambda x : len(x.split(' '))) #Number of words/group of characters seperated by a whitespace\n",
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer(max_features=feature_count) #tfidf = term frequency inverse document frequency\n",
    "items_df_item_name_text_features = pd.DataFrame(tfidf.fit_transform(items_df['item_name']).toarray())\n",
    "print(\"Shape of items_df_item_name_text_features : {}\".format(items_df_item_name_text_features.shape))\n",
    "cols = items_df_item_name_text_features.columns\n",
    "for idx in range(feature_count):\n",
    "    items_df['item_name_tfidf_' + str(idx)] = items_df_item_name_text_features[cols[idx]]\n",
    "\n",
    "feature_count = 25\n",
    "item_categories_df['item_categories_name_length'] = item_categories_df['item_category_name'].map(lambda x : len(x)) #Length of each item_category_name(including punctuation in the item_category_name)\n",
    "item_categories_df['item_categories_name_word_count'] = item_categories_df['item_category_name'].map(lambda x : len(x.split(' '))) #Number of words/group of characters seperated by a whitespace\n",
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer(max_features=feature_count) #tfidf = term frequency inverse document frequency\n",
    "item_categories_df_item_category_name_text_features = pd.DataFrame(tfidf.fit_transform(item_categories_df['item_category_name']).toarray())\n",
    "cols = item_categories_df_item_category_name_text_features.columns\n",
    "for idx in range(feature_count):\n",
    "    item_categories_df['item_category_name_tfidf_' + str(idx)] = item_categories_df_item_category_name_text_features[cols[idx]]\n",
    "\n",
    "\n",
    "feature_count = 25\n",
    "shops_df['shop_name_length'] = shops_df['shop_name'].map(lambda x : len(x)) #Length of each shop_name(including punctuation in the shop_name)\n",
    "shops_df['shop_name_word_count'] = shops_df['shop_name'].map(lambda x : len(x.split(' '))) #Number of words/group of characters seperated by a whitespace\n",
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer(max_features=feature_count) #tfidf = term frequency inverse document frequency\n",
    "shops_df_shop_name_text_features = pd.DataFrame(tfidf.fit_transform(shops_df['shop_name']).toarray())\n",
    "cols = shops_df_shop_name_text_features.columns\n",
    "for idx in range(feature_count):\n",
    "    shops_df['shop_name_tfidf_' + str(idx)] = shops_df_shop_name_text_features[cols[idx]]\n",
    "\n",
    "\n",
    "#turn data into monthly data\n",
    "train_df['date'] = pd.to_datetime(train_df['date'], format='%d.%m.%Y')\n",
    "train_df['month'] = train_df['date'].dt.month\n",
    "train_df['year'] = train_df['date'].dt.year\n",
    "train_df = train_df.drop(['date', 'item_price'], axis=1)\n",
    "train_df = train_df.groupby([c for c in train_df.columns if c not in ['item_cnt_day']], as_index=False)[['item_cnt_day']].sum()\n",
    "train_df = train_df.rename(columns={'item_cnt_day':'item_cnt_month'})\n",
    "\n",
    "#Monthly mean\n",
    "shop_item_monthly_mean = train_df[['shop_id', 'item_id', 'item_cnt_month']].groupby(['shop_id', 'item_id'], as_index=False)[['item_cnt_month']].mean()\n",
    "shop_item_monthly_mean = shop_item_monthly_mean.rename(columns={'item_cnt_month':'item_cnt_month_mean'})\n",
    "\n",
    "#Add Mean Features\n",
    "train_df = pd.merge(train_df, shop_item_monthly_mean, how='left', on=['shop_id', 'item_id'])\n",
    "\n",
    "#Last Month : Oct 2015\n",
    "shop_item_prev_month = train_df[train_df['date_block_num'] == 33][['shop_id', 'item_id', 'item_cnt_month']]\n",
    "shop_item_prev_month = shop_item_prev_month.rename(columns={'item_cnt_month':'item_cnt_prev_month'})\n",
    "shop_item_prev_month.head()\n",
    "\n",
    "#Add the above previous month features\n",
    "train_df = pd.merge(train_df, shop_item_prev_month, how='left', on=['shop_id', 'item_id'])\n",
    "\n",
    "np.where(pd.isnull(train_df))\n",
    "\n",
    "train_df = train_df.fillna(0.)\n",
    "\n",
    "#Add Item, Category and Shop features\n",
    "train_df = pd.merge(train_df, items_df, how='left', on='item_id')\n",
    "\n",
    "train_df = pd.merge(train_df, item_categories_df, how='left', on=['item_category_id'])\n",
    "\n",
    "train_df = pd.merge(train_df, shops_df, how='left', on=['shop_id'])\n",
    "\n",
    "#Manipulate test data\n",
    "test_df['month'] = 11\n",
    "test_df['year'] = 2015\n",
    "test_df['date_block_num'] = 34\n",
    "\n",
    "test_df = pd.merge(test_df, shop_item_monthly_mean, how='left', on=['shop_id', 'item_id'])\n",
    "\n",
    "#Add previous month features\n",
    "test_df = pd.merge(test_df, shop_item_prev_month, how='left', on=['shop_id', 'item_id'])\n",
    "\n",
    "#Items features\n",
    "test_df = pd.merge(test_df, items_df, how='left', on='item_id')\n",
    "\n",
    "#Item Category features\n",
    "test_df = pd.merge(test_df, item_categories_df, how='left', on='item_category_id')\n",
    "#Shops features\n",
    "test_df = pd.merge(test_df, shops_df, how='left', on='shop_id')\n",
    "test_df = test_df.fillna(0.)\n",
    "test_df['item_cnt_month'] = 0.\n",
    "\n",
    "\n",
    "#可视化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "train_test_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "stores_hm = train_test_df.pivot_table(index='shop_id', columns='item_category_id', values='item_cnt_month', aggfunc='count', fill_value=0)\n",
    "stores_hm.tail()\n",
    "\n",
    "#Heatmap of \"item_cnt_month\" in \"shop_id vs item_category_id\" in \"train_test_df\"\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(stores_hm, ax=ax, cbar=False)\n",
    "\n",
    "#Heatmap of \"item_cnt_month\" in \"shop_id vs item_category_id\" in \"train_df\"\n",
    "stores_hm = train_df.pivot_table(index='shop_id', columns='item_category_id', values='item_cnt_month', aggfunc='count', fill_value=0)\n",
    "_, ax = plt.subplots(figsize=(15, 15))\n",
    "sns.heatmap(stores_hm, ax=ax, cbar=False)\n",
    "\n",
    "#Heatmap of \"item_cnt_month\" in \"shop_id vs item_category_id\" in \"test_df\"\n",
    "stores_hm = test_df.pivot_table(index='shop_id', columns='item_category_id', values='item_cnt_month', aggfunc='count', fill_value=0)\n",
    "_, ax = plt.subplots(figsize=(15, 15))\n",
    "sns.heatmap(stores_hm, ax=ax, cbar=False)\n",
    "\n",
    "for c in ['shop_name', 'item_category_name', 'item_name']:\n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    le.fit(list(train_df[c].unique()) + list(test_df[c].unique()))\n",
    "    train_df[c] = le.transform(train_df[c].astype(str))\n",
    "    test_df[c] = le.transform(test_df[c].astype(str))\n",
    "    print(c)\n",
    "\n",
    "\n",
    "feature_list = [c for c in train_df.columns if c not in 'item_cnt_month']\n",
    "#Validation hold out month is 33\n",
    "x1 = train_df[train_df['date_block_num'] < 33]\n",
    "y1 = np.log1p(x1['item_cnt_month'].clip(0., 20.))\n",
    "x1 = x1[feature_list]\n",
    "x2 = train_df[train_df['date_block_num'] == 33]\n",
    "y2 = np.log1p(x2['item_cnt_month'].clip(0., 20.))\n",
    "x2 = x2[feature_list]\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=25, random_state=42, max_depth=15, n_jobs=-1)#use n_estimators=25, max_depth=15, random_state=42(for consistent results)\n",
    "rf.fit(x1, y1)\n",
    "print(\"RMSE on Validation hold out month 33: {}\".format(np.sqrt(sklearn.metrics.mean_squared_error(y2.clip(0., 20.), rf.predict(x2).clip(0., 20.)))))\n",
    "\n",
    "#Full train\n",
    "rf.fit(train_df[feature_list], train_df['item_cnt_month'].clip(0., 20.))\n",
    "print(\"Accuracy on training data without considering variable importances:{}\".format(round(rf.score(train_df[feature_list], train_df['item_cnt_month'].clip(0., 20.))*100, 2)))\n",
    "\n",
    "#predict\n",
    "test_df['item_cnt_month'] = rf.predict(test_df[feature_list]).clip(0., 20.)\n",
    "\n",
    "#create submission file\n",
    "test_df[['ID', 'item_cnt_month']].to_csv('submission.csv', index=False)\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "from IPython.display import Image\n",
    "\n",
    "#To see the decision tree in action, visualizing with a smaller one for illustrative purposes\n",
    "rf_small = RandomForestRegressor(n_estimators=2, random_state=42, max_depth=3, n_jobs=-1)\n",
    "rf_small.fit(train_df[feature_list], train_df['item_cnt_month'].clip(0., 20.))\n",
    "small_tree = rf_small.estimators_[1]\n",
    "export_graphviz(small_tree, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "graph.write_png('small_tree.png')\n",
    "Image(filename='small_tree.png')\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "#set size\n",
    "fig = plt.figure(figsize=(25, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "# Make a bar chart\n",
    "ax.bar(x_values, importances, orientation = 'vertical')\n",
    "\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical', fontsize=12)\n",
    "\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\n",
    "\n",
    "\n",
    "\n",
    "rf_most_important = RandomForestRegressor(n_estimators=25, random_state=42, max_depth=15, n_jobs=-1)\n",
    "\n",
    "# Extract the ten most important features\n",
    "important_features = ['item_cnt_month_mean', 'date_block_num', 'item_cnt_prev_month', 'item_id', 'item_name', 'item_name_length', 'year', 'item_name_word_count', 'item_name_tfidf_21', 'item_category_name_tfidf_6']\n",
    "\n",
    "#Full train\n",
    "rf_most_important.fit(train_df[important_features], train_df['item_cnt_month'].clip(0., 20.))\n",
    "print(\"Accuracy on training data considering variable importances:{}\".format(round(rf_most_important.score(train_df[important_features], train_df['item_cnt_month'].clip(0., 20.))*100, 2)))\n",
    "\n",
    "#predict\n",
    "test_df['item_cnt_month'] = rf_most_important.predict(test_df[important_features]).clip(0., 20.)\n",
    "\n",
    "#create submission file\n",
    "test_df[['ID', 'item_cnt_month']].to_csv('submission_variable_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
